TensorFlow 2.0 Upgrade Script
-----------------------------
Converted 1 files
Detected 4 issues that require attention
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
File: inp/model.py
--------------------------------------------------------------------------------
inp/model.py:33:19: WARNING: Using member tf.contrib.rnn.DropoutWrapper in deprecated module tf.contrib.rnn. (Manual edit required) tf.contrib.rnn.* has been deprecated, and widely used cells/functions will be moved to tensorflow/addons repository. Please check it there and file Github issues if necessary.
inp/model.py:33:19: ERROR: Using member tf.contrib.rnn.DropoutWrapper in deprecated module tf.contrib. tf.contrib.rnn.DropoutWrapper cannot be converted automatically. tf.contrib will not be distributed with TensorFlow 2.0, please consider an alternative in non-contrib TensorFlow, a community-maintained repository such as tensorflow/addons, or fork the required code.
inp/model.py:37:4: WARNING: tf.get_variable requires manual check. tf.get_variable returns ResourceVariables by default in 2.0, which have well-defined semantics and are stricter about shapes. You can disable this behavior by passing use_resource=False, or by calling tf.compat.v1.disable_resource_variables().
inp/model.py:38:4: WARNING: tf.get_variable requires manual check. tf.get_variable returns ResourceVariables by default in 2.0, which have well-defined semantics and are stricter about shapes. You can disable this behavior by passing use_resource=False, or by calling tf.compat.v1.disable_resource_variables().
================================================================================
Detailed log follows:

================================================================================
================================================================================
Input tree: 'inp/'
================================================================================
--------------------------------------------------------------------------------
Processing file 'inp/model.py'
 outputting to 'my_project_v2/model.py'
--------------------------------------------------------------------------------

27:21: INFO: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'
28:21: INFO: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'
31:14: INFO: Renamed 'tf.contrib.rnn.LSTMCell' to 'tf.compat.v1.nn.rnn_cell.LSTMCell'
31:95: INFO: Changing tf.contrib.layers xavier initializer to a tf.compat.v1.keras.initializers.VarianceScaling and converting arguments.

33:19: WARNING: Using member tf.contrib.rnn.DropoutWrapper in deprecated module tf.contrib.rnn. (Manual edit required) tf.contrib.rnn.* has been deprecated, and widely used cells/functions will be moved to tensorflow/addons repository. Please check it there and file Github issues if necessary.
33:19: ERROR: Using member tf.contrib.rnn.DropoutWrapper in deprecated module tf.contrib. tf.contrib.rnn.DropoutWrapper cannot be converted automatically. tf.contrib will not be distributed with TensorFlow 2.0, please consider an alternative in non-contrib TensorFlow, a community-maintained repository such as tensorflow/addons, or fork the required code.
34:18: INFO: Renamed 'tf.contrib.rnn.MultiRNNCell' to 'tf.compat.v1.nn.rnn_cell.MultiRNNCell'
35:13: INFO: Renamed 'tf.contrib.rnn.MultiRNNCell' to 'tf.compat.v1.nn.rnn_cell.MultiRNNCell'
37:4: WARNING: tf.get_variable requires manual check. tf.get_variable returns ResourceVariables by default in 2.0, which have well-defined semantics and are stricter about shapes. You can disable this behavior by passing use_resource=False, or by calling tf.compat.v1.disable_resource_variables().
37:4: INFO: Renamed 'tf.get_variable' to 'tf.compat.v1.get_variable'
37:62: INFO: Changing tf.contrib.layers xavier initializer to a tf.compat.v1.keras.initializers.VarianceScaling and converting arguments.

38:4: WARNING: tf.get_variable requires manual check. tf.get_variable returns ResourceVariables by default in 2.0, which have well-defined semantics and are stricter about shapes. You can disable this behavior by passing use_resource=False, or by calling tf.compat.v1.disable_resource_variables().
38:4: INFO: Renamed 'tf.get_variable' to 'tf.compat.v1.get_variable'
38:36: INFO: Renamed 'tf.random_uniform' to 'tf.random.uniform'
47:23: INFO: Renamed 'tf.contrib.rnn.LSTMStateTuple' to 'tf.nn.rnn_cell.LSTMStateTuple'
53:26: INFO: Renamed 'tf.nn.dynamic_rnn' to 'tf.compat.v1.nn.dynamic_rnn'
59:14: INFO: Renamed 'tf.nn.xw_plus_b' to 'tf.compat.v1.nn.xw_plus_b'
67:30: INFO: Renamed 'tf.assign' to 'tf.compat.v1.assign'
68:30: INFO: Renamed 'tf.assign' to 'tf.compat.v1.assign'
70:12: INFO: Added keywords to args of function 'tf.reduce_mean'
74:12: INFO: Renamed 'tf.assign' to 'tf.compat.v1.assign'
75:19: INFO: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'
76:23: INFO: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'
79:4: INFO: tf.train.exponential_decay requires manual check. To use learning rate decay schedules with TensorFlow 2.0, switch to the schedules in `tf.keras.optimizers.schedules`.

79:4: INFO: Renamed 'tf.train.exponential_decay' to 'tf.compat.v1.train.exponential_decay'
84:12: INFO: Renamed 'tf.train.AdamOptimizer' to 'tf.compat.v1.train.AdamOptimizer'
93:16: INFO: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'
100:30: INFO: Renamed 'tf.contrib.rnn.LSTMStateTuple' to 'tf.nn.rnn_cell.LSTMStateTuple'
102:33: INFO: Renamed 'tf.assign' to 'tf.compat.v1.assign'
103:33: INFO: Renamed 'tf.assign' to 'tf.compat.v1.assign'
105:31: INFO: Renamed 'tf.nn.dynamic_rnn' to 'tf.compat.v1.nn.dynamic_rnn'
110:30: INFO: Renamed 'tf.assign' to 'tf.compat.v1.assign'
111:31: INFO: Renamed 'tf.assign' to 'tf.compat.v1.assign'
112:22: INFO: Renamed 'tf.nn.xw_plus_b' to 'tf.compat.v1.nn.xw_plus_b'
130:10: INFO: Renamed 'tf.InteractiveSession' to 'tf.compat.v1.InteractiveSession'
132:0: INFO: Renamed 'tf.global_variables_initializer' to 'tf.compat.v1.global_variables_initializer'
--------------------------------------------------------------------------------

